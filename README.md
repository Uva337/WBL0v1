# Сервис обработки и хранения заказов

Демонстрационный сервис, который в реальном времени получает данные о заказах из потока **Kafka**, сохраняет их в **PostgreSQL** и предоставляет быстрый доступ к ним через **in-memory кеш** и **REST API**.

## Ключевые возможности

* **Потоковая обработка:** Асинхронное получение и обработка заказов из топика Kafka.
* **Персистентное хранилище:** Надежное сохранение данных в PostgreSQL с использованием формата JSONB.
* **Кеширование:** In-memory кеш с автоматическим удалением по времени (TTL) для минимизации задержек при повторных запросах.
* **REST API:** Простой API-ендпоинт для получения данных заказа по его уникальному идентификатору.
* **Веб-интерфейс:** Интерактивная веб-страница для удобного тестирования API.
* **Генерация данных:** Утилита для генерации тестовых данных с использованием `gofakeit`.
* **Контейнеризация:** Полная настройка окружения с помощью Docker Compose для быстрого развертывания.

---

## Архитектура

Сервис построен по следующей схеме:

1.  **Producer (`make send`)**: Утилита генерирует случайные данные о заказах и отправляет их в виде JSON-сообщений в топик `orders` в Kafka.
2.  **Kafka**: Выступает в роли брокера сообщений, принимая данные от Producer и передавая их Consumer'у.
3.  **Consumer (Основное приложение `make run`)**:
    * Подписывается на топик `orders`.
    * При получении сообщения, валидирует его структуру и данные.
    * Сохраняет валидный заказ в базу данных PostgreSQL.
    * Помещает сохраненный заказ в кеш.
4.  **PostgreSQL**: Является основным, долгосрочным хранилищем всех заказов.
5.  **In-memory Cache**: Хранит недавно обработанные заказы для обеспечения мгновенного доступа.
6.  **HTTP Server (Основное приложение `make run`)**:
    * Предоставляет REST API (`GET /api/order/:id`) для получения заказов.
    * При запросе сначала проверяет наличие заказа в кеше. Если его там нет — обращается к PostgreSQL.
    * Отдает статичный веб-интерфейс для взаимодействия с API.

---

## Технологический стек

* **Язык:** Go
* **База данных:** PostgreSQL
* **Брокер сообщений:** Apache Kafka
* **Кеширование:** `go-cache` (in-memory)
* **Валидация:** `go-playground/validator`
* **Генерация данных:** `gofakeit`
* **Развертывание:** Docker, Docker Compose
* **Тестирование:** `testify` (unit-тесты, моки)

---

## Быстрый старт

### 1. Предварительные требования

* Установленный Docker и Docker Compose.
* Установленный Go (версия 1.22+).
* Установленная утилита `make`.

### 2. Конфигурация

Проект использует переменные окружения. Для локального запуска создайте файл `.env` из примера.

```bash
cp .env.example .env
```
*В большинстве случаев изменять стандартные значения в `.env` не требуется.*

### 3. Запуск

Следуйте командам в указанном порядке.

1.  **Запустить все сервисы (PostgreSQL, Kafka):**
    ```bash
    make all-up
    ```
    *Эта команда автоматически сделает паузу, чтобы Kafka успел инициализироваться.*

2.  **Применить миграции к базе данных:**
    ```bash
    make migrate
    ```

3.  **Запустить основное приложение (сервер и консьюмер):**
    *Откройте **первый** терминал и выполните:*
    ```bash
    make run
    ```
    *Приложение запустится и будет ждать сообщений из Kafka.*

4.  **Сгенерировать и отправить тестовые данные:**
    *Откройте **второй** терминал и выполните:*
    ```bash
    make send
    ```
    *В консоли отобразятся ID сгенерированных заказов.*

---

## Использование

1.  Откройте в браузере `http://localhost:8081`.
2.  Скопируйте любой `OrderUID` из вывода команды `make send`.
3.  Вставьте его в поле ввода на странице и нажмите "Получить заказ".
4.  Ниже отобразятся полные данные заказа в формате JSON.

### Тестирование

Для запуска юнит-тестов выполните команду:
```bash
make test
```